diff -rU5 ./openssl-1.0.1-beta3/Configure ./openssl-1.0.1-beta3-modified/Configure
--- ./openssl-1.0.1-beta3/Configure	2012-02-01 23:42:30.000000000 -0800
+++ ./openssl-1.0.1-beta3-modified/Configure	2012-02-24 15:06:55.000000000 -0800
@@ -406,10 +406,11 @@
 "android-x86","gcc:-mandroid -I\$(ANDROID_DEV)/include -B\$(ANDROID_DEV)/lib -O3 -fomit-frame-pointer -Wall::-D_REENTRANT::-ldl:BN_LLONG ${x86_gcc_des} ${x86_gcc_opts}:".eval{my $asm=${x86_elf_asm};$asm=~s/:elf/:android/;$asm}.":dlfcn:linux-shared:-fPIC::.so.\$(SHLIB_MAJOR).\$(SHLIB_MINOR)",
 "android-armv7","gcc:-march=armv7-a -mandroid -I\$(ANDROID_DEV)/include -B\$(ANDROID_DEV)/lib -O3 -fomit-frame-pointer -Wall::-D_REENTRANT::-ldl:BN_LLONG RC4_CHAR RC4_CHUNK DES_INT DES_UNROLL BF_PTR:${armv4_asm}:dlfcn:linux-shared:-fPIC::.so.\$(SHLIB_MAJOR).\$(SHLIB_MINOR)",
 
 #### *BSD [do see comment about ${BSDthreads} above!]
 "BSD-generic32","gcc:-DTERMIOS -O3 -fomit-frame-pointer -Wall::${BSDthreads}:::BN_LLONG RC2_CHAR RC4_INDEX DES_INT DES_UNROLL:${no_asm}:dlfcn:bsd-gcc-shared:-fPIC::.so.\$(SHLIB_MAJOR).\$(SHLIB_MINOR)",
+"BSD-arm","gcc:-DTERMIOS -O3 -fomit-frame-pointer -Wall::${BSDthreads}:::BN_LLONG RC2_CHAR RC4_INDEX DES_INT DES_UNROLL:mem_clr.o ${armv4_asm}:dlfcn:bsd-gcc-shared:-fPIC::.so.\$(SHLIB_MAJOR).\$(SHLIB_MINOR)",
 "BSD-x86",	"gcc:-DL_ENDIAN -DTERMIOS -O3 -fomit-frame-pointer -Wall::${BSDthreads}:::BN_LLONG ${x86_gcc_des} ${x86_gcc_opts}:${x86_asm}:a.out:dlfcn:bsd-shared:-fPIC::.so.\$(SHLIB_MAJOR).\$(SHLIB_MINOR)",
 "BSD-x86-elf",	"gcc:-DL_ENDIAN -DTERMIOS -O3 -fomit-frame-pointer -Wall::${BSDthreads}:::BN_LLONG ${x86_gcc_des} ${x86_gcc_opts}:${x86_elf_asm}:dlfcn:bsd-shared:-fPIC::.so.\$(SHLIB_MAJOR).\$(SHLIB_MINOR)",
 "debug-BSD-x86-elf",	"gcc:-DL_ENDIAN -DTERMIOS -O3 -Wall -g::${BSDthreads}:::BN_LLONG ${x86_gcc_des} ${x86_gcc_opts}:${x86_elf_asm}:dlfcn:bsd-shared:-fPIC::.so.\$(SHLIB_MAJOR).\$(SHLIB_MINOR)",
 "BSD-sparcv8",	"gcc:-DB_ENDIAN -DTERMIOS -O3 -mv8 -Wall::${BSDthreads}:::BN_LLONG RC2_CHAR RC4_INDEX DES_INT DES_UNROLL:${sparcv8_asm}:dlfcn:bsd-gcc-shared:-fPIC::.so.\$(SHLIB_MAJOR).\$(SHLIB_MINOR)",
 
diff -rU5 ./openssl-1.0.1-beta3/crypto/aes/asm/aes-armv4.pl ./openssl-1.0.1-beta3-modified/crypto/aes/asm/aes-armv4.pl
--- ./openssl-1.0.1-beta3/crypto/aes/asm/aes-armv4.pl	2011-11-15 05:55:52.000000000 -0800
+++ ./openssl-1.0.1-beta3-modified/crypto/aes/asm/aes-armv4.pl	2012-02-24 15:48:58.000000000 -0800
@@ -53,11 +53,11 @@
 $code=<<___;
 #include "arm_arch.h"
 .text
 .code	32
 
-.type	AES_Te,%object
+@.type	AES_Te,%object
 .align	5
 AES_Te:
 .word	0xc66363a5, 0xf87c7c84, 0xee777799, 0xf67b7b8d
 .word	0xfff2f20d, 0xd66b6bbd, 0xde6f6fb1, 0x91c5c554
 .word	0x60303050, 0x02010103, 0xce6767a9, 0x562b2b7d
@@ -157,23 +157,24 @@
 .byte	0x41, 0x99, 0x2d, 0x0f, 0xb0, 0x54, 0xbb, 0x16
 @ rcon[]
 .word	0x01000000, 0x02000000, 0x04000000, 0x08000000
 .word	0x10000000, 0x20000000, 0x40000000, 0x80000000
 .word	0x1B000000, 0x36000000, 0, 0, 0, 0, 0, 0
-.size	AES_Te,.-AES_Te
+@.size	AES_Te,.-AES_Te
 
-@ void AES_encrypt(const unsigned char *in, unsigned char *out,
+@ void _AES_encrypt(const unsigned char *in, unsigned char *out,
 @ 		 const AES_KEY *key) {
-.global AES_encrypt
-.type   AES_encrypt,%function
+.globl _AES_encrypt
+@.type   _AES_encrypt,%function
 .align	5
-AES_encrypt:
-	sub	r3,pc,#8		@ AES_encrypt
+_AES_encrypt:
+	sub	r3,pc,#8		@ _AES_encrypt
 	stmdb   sp!,{r1,r4-r12,lr}
 	mov	$rounds,r0		@ inp
 	mov	$key,r2
-	sub	$tbl,r3,#AES_encrypt-AES_Te	@ Te
+	@ sub	$tbl,r3,#_AES_encrypt-AES_Te	@ Te
+    ldr $tbl,_AES_encrypt @ or adr?
 #if __ARM_ARCH__<7
 	ldrb	$s0,[$rounds,#3]	@ load input data in endian-neutral
 	ldrb	$t1,[$rounds,#2]	@ manner...
 	ldrb	$t2,[$rounds,#1]
 	ldrb	$t3,[$rounds,#0]
@@ -263,13 +264,13 @@
 	ldmia   sp!,{r4-r12,lr}
 	tst	lr,#1
 	moveq	pc,lr			@ be binary compatible with V4, yet
 	bx	lr			@ interoperable with Thumb ISA:-)
 #endif
-.size	AES_encrypt,.-AES_encrypt
+@.size	_AES_encrypt,.-_AES_encrypt
 
-.type   _armv4_AES_encrypt,%function
+@.type   _armv4_AES_encrypt,%function
 .align	2
 _armv4_AES_encrypt:
 	str	lr,[sp,#-4]!		@ push lr
 	ldmia	$key!,{$t1-$i1}
 	eor	$s0,$s0,$t1
@@ -400,16 +401,16 @@
 	eor	$s2,$s2,$t2
 	eor	$s3,$s3,$t3
 
 	sub	$tbl,$tbl,#2
 	ldr	pc,[sp],#4		@ pop and return
-.size	_armv4_AES_encrypt,.-_armv4_AES_encrypt
+@.size	_armv4_AES_encrypt,.-_armv4_AES_encrypt
 
-.global private_AES_set_encrypt_key
-.type   private_AES_set_encrypt_key,%function
+.globl _private_AES_set_encrypt_key
+@.type   _private_AES_set_encrypt_key,%function
 .align	5
-private_AES_set_encrypt_key:
+_private_AES_set_encrypt_key:
 	sub	r3,pc,#8		@ AES_set_encrypt_key
 	teq	r0,#0
 	moveq	r0,#-1
 	beq	.Labrt
 	teq	r2,#0
@@ -423,11 +424,12 @@
 	teq	r1,#256
 	movne	r0,#-1
 	bne	.Labrt
 
 .Lok:	stmdb   sp!,{r4-r12,lr}
-	sub	$tbl,r3,#private_AES_set_encrypt_key-AES_Te-1024	@ Te4
+	@ sub	$tbl,r3,#_private_AES_set_encrypt_key-AES_Te-1024	@ Te4
+    ldr $tbl,_private_AES_set_encrypt_key @ or adr?
 
 	mov	$rounds,r0		@ inp
 	mov	lr,r1			@ bits
 	mov	$key,r2			@ key
 
@@ -676,18 +678,18 @@
 .Ldone:	mov	r0,#0
 	ldmia   sp!,{r4-r12,lr}
 .Labrt:	tst	lr,#1
 	moveq	pc,lr			@ be binary compatible with V4, yet
 	bx	lr			@ interoperable with Thumb ISA:-)
-.size	private_AES_set_encrypt_key,.-private_AES_set_encrypt_key
+@.size	_private_AES_set_encrypt_key,.-_private_AES_set_encrypt_key
 
-.global private_AES_set_decrypt_key
-.type   private_AES_set_decrypt_key,%function
+.globl _private_AES_set_decrypt_key
+@.type   _private_AES_set_decrypt_key,%function
 .align	5
-private_AES_set_decrypt_key:
+_private_AES_set_decrypt_key:
 	str	lr,[sp,#-4]!            @ push lr
-	bl	private_AES_set_encrypt_key
+	bl	_private_AES_set_encrypt_key
 	teq	r0,#0
 	ldrne	lr,[sp],#4              @ pop lr
 	bne	.Labrt
 
 	stmdb   sp!,{r4-r12}
@@ -770,13 +772,13 @@
 	ldmia   sp!,{r4-r12,lr}
 	tst	lr,#1
 	moveq	pc,lr			@ be binary compatible with V4, yet
 	bx	lr			@ interoperable with Thumb ISA:-)
 #endif
-.size	private_AES_set_decrypt_key,.-private_AES_set_decrypt_key
+@.size	_private_AES_set_decrypt_key,.-_private_AES_set_decrypt_key
 
-.type	AES_Td,%object
+@.type	AES_Td,%object
 .align	5
 AES_Td:
 .word	0x51f4a750, 0x7e416553, 0x1a17a4c3, 0x3a275e96
 .word	0x3bab6bcb, 0x1f9d45f1, 0xacfa58ab, 0x4be30393
 .word	0x2030fa55, 0xad766df6, 0x88cc7691, 0xf5024c25
@@ -872,23 +874,24 @@
 .byte	0x2d, 0xe5, 0x7a, 0x9f, 0x93, 0xc9, 0x9c, 0xef
 .byte	0xa0, 0xe0, 0x3b, 0x4d, 0xae, 0x2a, 0xf5, 0xb0
 .byte	0xc8, 0xeb, 0xbb, 0x3c, 0x83, 0x53, 0x99, 0x61
 .byte	0x17, 0x2b, 0x04, 0x7e, 0xba, 0x77, 0xd6, 0x26
 .byte	0xe1, 0x69, 0x14, 0x63, 0x55, 0x21, 0x0c, 0x7d
-.size	AES_Td,.-AES_Td
+@.size	AES_Td,.-AES_Td
 
-@ void AES_decrypt(const unsigned char *in, unsigned char *out,
+@ void _AES_decrypt(const unsigned char *in, unsigned char *out,
 @ 		 const AES_KEY *key) {
-.global AES_decrypt
-.type   AES_decrypt,%function
+.globl _AES_decrypt
+@.type   _AES_decrypt,%function
 .align	5
-AES_decrypt:
-	sub	r3,pc,#8		@ AES_decrypt
+_AES_decrypt:
+	sub	r3,pc,#8		@ _AES_decrypt
 	stmdb   sp!,{r1,r4-r12,lr}
 	mov	$rounds,r0		@ inp
 	mov	$key,r2
-	sub	$tbl,r3,#AES_decrypt-AES_Td		@ Td
+	@ sub	$tbl,r3,#_AES_decrypt-AES_Td		@ Td
+    ldr $tbl,_AES_decrypt @ or adr?
 #if __ARM_ARCH__<7
 	ldrb	$s0,[$rounds,#3]	@ load input data in endian-neutral
 	ldrb	$t1,[$rounds,#2]	@ manner...
 	ldrb	$t2,[$rounds,#1]
 	ldrb	$t3,[$rounds,#0]
@@ -978,13 +981,13 @@
 	ldmia   sp!,{r4-r12,lr}
 	tst	lr,#1
 	moveq	pc,lr			@ be binary compatible with V4, yet
 	bx	lr			@ interoperable with Thumb ISA:-)
 #endif
-.size	AES_decrypt,.-AES_decrypt
+@.size	_AES_decrypt,.-_AES_decrypt
 
-.type   _armv4_AES_decrypt,%function
+@.type   _armv4_AES_decrypt,%function
 .align	2
 _armv4_AES_decrypt:
 	str	lr,[sp,#-4]!		@ push lr
 	ldmia	$key!,{$t1-$i1}
 	eor	$s0,$s0,$t1
@@ -1121,11 +1124,11 @@
 	eor	$s2,$s2,$t2
 	eor	$s3,$s3,$t3
 
 	sub	$tbl,$tbl,#1024
 	ldr	pc,[sp],#4		@ pop and return
-.size	_armv4_AES_decrypt,.-_armv4_AES_decrypt
+@.size	_armv4_AES_decrypt,.-_armv4_AES_decrypt
 .asciz	"AES for ARMv4, CRYPTOGAMS by <appro\@openssl.org>"
 .align	2
 ___
 
 $code =~ s/\bbx\s+lr\b/.word\t0xe12fff1e/gm;	# make it possible to compile with -march=armv4
diff -rU5 ./openssl-1.0.1-beta3/crypto/armv4cpuid.S ./openssl-1.0.1-beta3-modified/crypto/armv4cpuid.S
--- ./openssl-1.0.1-beta3/crypto/armv4cpuid.S	2011-11-14 12:58:00.000000000 -0800
+++ ./openssl-1.0.1-beta3-modified/crypto/armv4cpuid.S	2012-02-24 16:59:45.000000000 -0800
@@ -2,26 +2,26 @@
 
 .text
 .code	32
 
 .align	5
-.global	_armv7_neon_probe
-.type	_armv7_neon_probe,%function
-_armv7_neon_probe:
+.globl	__armv7_neon_probe
+@.type	__armv7_neon_probe,%function
+__armv7_neon_probe:
 	.word	0xf26ee1fe	@ vorr	q15,q15,q15
 	.word	0xe12fff1e	@ bx	lr
-.size	_armv7_neon_probe,.-_armv7_neon_probe
+@.size	__armv7_neon_probe,.-__armv7_neon_probe
 
-.global	_armv7_tick
-.type	_armv7_tick,%function
-_armv7_tick:
+.globl	__armv7_tick
+@.type	__armv7_tick,%function
+__armv7_tick:
 	mrc	p15,0,r0,c9,c13,0
 	.word	0xe12fff1e	@ bx	lr
-.size	_armv7_tick,.-_armv7_tick
+@.size	__armv7_tick,.-__armv7_tick
 
-.global	OPENSSL_atomic_add
-.type	OPENSSL_atomic_add,%function
+.globl	OPENSSL_atomic_add
+@.type	OPENSSL_atomic_add,%function
 OPENSSL_atomic_add:
 #if __ARM_ARCH__>=6
 .Ladd:	ldrex	r2,[r0]
 	add	r3,r2,r1
 	strex	r2,r3,[r0]
@@ -50,14 +50,14 @@
 	ldmia	sp!,{r4-r6,lr}
 	tst	lr,#1
 	moveq	pc,lr
 	.word	0xe12fff1e	@ bx	lr
 #endif
-.size	OPENSSL_atomic_add,.-OPENSSL_atomic_add
+@.size	OPENSSL_atomic_add,.-OPENSSL_atomic_add
 
-.global	OPENSSL_cleanse
-.type	OPENSSL_cleanse,%function
+.globl	OPENSSL_cleanse
+@.type	OPENSSL_cleanse,%function
 OPENSSL_cleanse:
 	eor	ip,ip,ip
 	cmp	r1,#7
 	subhs	r1,r1,#4
 	bhs	.Lot
@@ -82,14 +82,14 @@
 	bne	.Little
 .Lcleanse_done:
 	tst	lr,#1
 	moveq	pc,lr
 	.word	0xe12fff1e	@ bx	lr
-.size	OPENSSL_cleanse,.-OPENSSL_cleanse
+@.size	OPENSSL_cleanse,.-OPENSSL_cleanse
 
-.global	OPENSSL_wipe_cpu
-.type	OPENSSL_wipe_cpu,%function
+.globl	OPENSSL_wipe_cpu
+@.type	OPENSSL_wipe_cpu,%function
 OPENSSL_wipe_cpu:
 	ldr	r0,.LOPENSSL_armcap
 	adr	r1,.LOPENSSL_armcap
 	ldr	r0,[r1,r0]
 	eor	r2,r2,r2
@@ -112,33 +112,33 @@
 .Lwipe_done:
 	mov	r0,sp
 	tst	lr,#1
 	moveq	pc,lr
 	.word	0xe12fff1e	@ bx	lr
-.size	OPENSSL_wipe_cpu,.-OPENSSL_wipe_cpu
+@.size	OPENSSL_wipe_cpu,.-OPENSSL_wipe_cpu
 
-.global	OPENSSL_instrument_bus
-.type	OPENSSL_instrument_bus,%function
+.globl	OPENSSL_instrument_bus
+@.type	OPENSSL_instrument_bus,%function
 OPENSSL_instrument_bus:
 	eor	r0,r0,r0
 	tst	lr,#1
 	moveq	pc,lr
 	.word	0xe12fff1e	@ bx	lr
-.size	OPENSSL_instrument_bus,.-OPENSSL_instrument_bus
+@.size	OPENSSL_instrument_bus,.-OPENSSL_instrument_bus
 
-.global	OPENSSL_instrument_bus2
-.type	OPENSSL_instrument_bus2,%function
+.globl	OPENSSL_instrument_bus2
+@.type	OPENSSL_instrument_bus2,%function
 OPENSSL_instrument_bus2:
 	eor	r0,r0,r0
 	tst	lr,#1
 	moveq	pc,lr
 	.word	0xe12fff1e	@ bx	lr
-.size	OPENSSL_instrument_bus2,.-OPENSSL_instrument_bus2
+@.size	OPENSSL_instrument_bus2,.-OPENSSL_instrument_bus2
 
 .align	5
 .LOPENSSL_armcap:
-.word	OPENSSL_armcap_P-.LOPENSSL_armcap
+.word	_OPENSSL_armcap_P-.LOPENSSL_armcap
 #if __ARM_ARCH__>=6
 .align	5
 #else
 .Lspinlock:
 .word	atomic_add_spinlock-.Lspinlock
@@ -148,7 +148,7 @@
 .align	2
 atomic_add_spinlock:
 .word	0
 #endif
 
-.comm	OPENSSL_armcap_P,4,4
-.hidden	OPENSSL_armcap_P
+.lcomm	_OPENSSL_armcap_P,4,4
+.private_extern _OPENSSL_armcap_P
diff -rU5 ./openssl-1.0.1-beta3/crypto/bn/asm/armv4-gf2m.pl ./openssl-1.0.1-beta3-modified/crypto/bn/asm/armv4-gf2m.pl
--- ./openssl-1.0.1-beta3/crypto/bn/asm/armv4-gf2m.pl	2011-11-14 12:58:00.000000000 -0800
+++ ./openssl-1.0.1-beta3-modified/crypto/bn/asm/armv4-gf2m.pl	2012-02-24 17:00:58.000000000 -0800
@@ -33,13 +33,13 @@
 
 .text
 .code	32
 
 #if __ARM_ARCH__>=7
-.fpu	neon
+@.fpu	neon
 
-.type	mul_1x1_neon,%function
+@.type	mul_1x1_neon,%function
 .align	5
 mul_1x1_neon:
 	vshl.u64	`&Dlo("q1")`,d16,#8	@ q1-q3 are slided $a
 	vmull.p8	`&Q("d0")`,d16,d17	@ a·bb
 	vshl.u64	`&Dlo("q2")`,d16,#16
@@ -58,11 +58,11 @@
 	veor		d0,`&Dhi("q2")`
 	vshl.u64	`&Dhi("q3")`,#8
 	veor		d0,`&Dlo("q3")`
 	veor		d0,`&Dhi("q3")`
 	bx	lr
-.size	mul_1x1_neon,.-mul_1x1_neon
+@.size	mul_1x1_neon,.-mul_1x1_neon
 #endif
 ___
 ################
 # private interface to mul_1x1_ialu
 #
@@ -73,11 +73,11 @@
 ($hi,$lo,$t0,$t1, $i0,$i1 )=map("r$_",(4..9),12);
 
 $mask="r12";
 
 $code.=<<___;
-.type	mul_1x1_ialu,%function
+@.type	mul_1x1_ialu,%function
 .align	5
 mul_1x1_ialu:
 	mov	$a0,#0
 	bic	$a1,$a,#3<<30		@ a1=a&0x3fffffff
 	str	$a0,[sp,#0]		@ tab[0]=0
@@ -151,24 +151,24 @@
 	eorne	$hi,$hi,$b,lsr#1
 	eor	$lo,$lo,$t0,lsl#30
 	eor	$hi,$hi,$t0,lsr#2
 
 	mov	pc,lr
-.size	mul_1x1_ialu,.-mul_1x1_ialu
+@.size	mul_1x1_ialu,.-mul_1x1_ialu
 ___
 ################
-# void	bn_GF2m_mul_2x2(BN_ULONG *r,
+# void	_bn_GF2m_mul_2x2(BN_ULONG *r,
 #	BN_ULONG a1,BN_ULONG a0,
 #	BN_ULONG b1,BN_ULONG b0);	# r[3..0]=a1a0·b1b0
 
 ($A1,$B1,$A0,$B0,$A1B1,$A0B0)=map("d$_",(18..23));
 
 $code.=<<___;
-.global	bn_GF2m_mul_2x2
-.type	bn_GF2m_mul_2x2,%function
+.globl	_bn_GF2m_mul_2x2
+@.type	_bn_GF2m_mul_2x2,%function
 .align	5
-bn_GF2m_mul_2x2:
+_bn_GF2m_mul_2x2:
 #if __ARM_ARCH__>=7
 	ldr	r12,.LOPENSSL_armcap
 .Lpic:	ldr	r12,[pc,r12]
 	tst	r12,#1
 	beq	.Lialu
@@ -258,20 +258,20 @@
 	ldmia	sp!,{r4-r10,lr}
 	tst	lr,#1
 	moveq	pc,lr			@ be binary compatible with V4, yet
 	bx	lr			@ interoperable with Thumb ISA:-)
 #endif
-.size	bn_GF2m_mul_2x2,.-bn_GF2m_mul_2x2
+@.size	_bn_GF2m_mul_2x2,.-_bn_GF2m_mul_2x2
 #if __ARM_ARCH__>=7
 .align	5
 .LOPENSSL_armcap:
-.word	OPENSSL_armcap_P-(.Lpic+8)
+.word	_OPENSSL_armcap_P-(.Lpic+8)
 #endif
 .asciz	"GF(2^m) Multiplication for ARMv4/NEON, CRYPTOGAMS by <appro\@openssl.org>"
 .align	5
 
-.comm	OPENSSL_armcap_P,4,4
+.lcomm	_OPENSSL_armcap_P,4,4
 ___
 
 $code =~ s/\`([^\`]*)\`/eval $1/gem;
 $code =~ s/\bbx\s+lr\b/.word\t0xe12fff1e/gm;    # make it possible to compile with -march=armv4
 print $code;
diff -rU5 ./openssl-1.0.1-beta3/crypto/bn/asm/armv4-mont.pl ./openssl-1.0.1-beta3-modified/crypto/bn/asm/armv4-mont.pl
--- ./openssl-1.0.1-beta3/crypto/bn/asm/armv4-mont.pl	2011-11-14 12:58:00.000000000 -0800
+++ ./openssl-1.0.1-beta3-modified/crypto/bn/asm/armv4-mont.pl	2012-02-24 15:53:51.000000000 -0800
@@ -52,15 +52,15 @@
 $_num="$num,#15*4";	$_bpend=$_num;
 
 $code=<<___;
 .text
 
-.global	bn_mul_mont
-.type	bn_mul_mont,%function
+.globl	_bn_mul_mont
+@.type	_bn_mul_mont,%function
 
 .align	2
-bn_mul_mont:
+_bn_mul_mont:
 	stmdb	sp!,{r0,r2}		@ sp points at argument block
 	ldr	$num,[sp,#3*4]		@ load num
 	cmp	$num,#2
 	movlt	r0,#0
 	addlt	sp,sp,#2*4
@@ -192,11 +192,11 @@
 	add	sp,sp,#2*4		@ skip over {r0,r2}
 	mov	r0,#1
 .Labrt:	tst	lr,#1
 	moveq	pc,lr			@ be binary compatible with V4, yet
 	bx	lr			@ interoperable with Thumb ISA:-)
-.size	bn_mul_mont,.-bn_mul_mont
+@.size	_bn_mul_mont,.-_bn_mul_mont
 .asciz	"Montgomery multiplication for ARMv4, CRYPTOGAMS by <appro\@openssl.org>"
 .align	2
 ___
 
 $code =~ s/\bbx\s+lr\b/.word\t0xe12fff1e/gm;	# make it possible to compile with -march=armv4
diff -rU5 ./openssl-1.0.1-beta3/crypto/modes/asm/ghash-armv4.pl ./openssl-1.0.1-beta3-modified/crypto/modes/asm/ghash-armv4.pl
--- ./openssl-1.0.1-beta3/crypto/modes/asm/ghash-armv4.pl	2011-08-11 15:36:18.000000000 -0700
+++ ./openssl-1.0.1-beta3-modified/crypto/modes/asm/ghash-armv4.pl	2012-02-24 15:53:04.000000000 -0800
@@ -76,11 +76,11 @@
 $nlo="r12";
 ################# r13 is stack pointer
 $nhi="r14";
 ################# r15 is program counter
 
-$rem_4bit=$inp;	# used in gcm_gmult_4bit
+$rem_4bit=$inp;	# used in _gcm_gmult_4bit
 $cnt=$len;
 
 sub Zsmash() {
   my $i=12;
   my @args=@_;
@@ -110,30 +110,30 @@
 #include "arm_arch.h"
 
 .text
 .code	32
 
-.type	rem_4bit,%object
+@.type	rem_4bit,%object
 .align	5
 rem_4bit:
 .short	0x0000,0x1C20,0x3840,0x2460
 .short	0x7080,0x6CA0,0x48C0,0x54E0
 .short	0xE100,0xFD20,0xD940,0xC560
 .short	0x9180,0x8DA0,0xA9C0,0xB5E0
-.size	rem_4bit,.-rem_4bit
+@.size	rem_4bit,.-rem_4bit
 
-.type	rem_4bit_get,%function
+@.type	rem_4bit_get,%function
 rem_4bit_get:
 	sub	$rem_4bit,pc,#8
 	sub	$rem_4bit,$rem_4bit,#32	@ &rem_4bit
 	b	.Lrem_4bit_got
 	nop
-.size	rem_4bit_get,.-rem_4bit_get
+@.size	rem_4bit_get,.-rem_4bit_get
 
-.global	gcm_ghash_4bit
-.type	gcm_ghash_4bit,%function
-gcm_ghash_4bit:
+.globl	_gcm_ghash_4bit
+@.type	_gcm_ghash_4bit,%function
+_gcm_ghash_4bit:
 	sub	r12,pc,#8
 	add	$len,$inp,$len		@ $len to point at the end
 	stmdb	sp!,{r3-r11,lr}		@ save $len/end too
 	sub	r12,r12,#48		@ &rem_4bit
 
@@ -221,15 +221,15 @@
 	ldmia	sp!,{r4-r11,lr}
 	tst	lr,#1
 	moveq	pc,lr			@ be binary compatible with V4, yet
 	bx	lr			@ interoperable with Thumb ISA:-)
 #endif
-.size	gcm_ghash_4bit,.-gcm_ghash_4bit
+@.size	_gcm_ghash_4bit,.-_gcm_ghash_4bit
 
-.global	gcm_gmult_4bit
-.type	gcm_gmult_4bit,%function
-gcm_gmult_4bit:
+.globl	_gcm_gmult_4bit
+@.type	_gcm_gmult_4bit,%function
+_gcm_gmult_4bit:
 	stmdb	sp!,{r4-r11,lr}
 	ldrb	$nlo,[$Xi,#15]
 	b	rem_4bit_get
 .Lrem_4bit_got:
 	and	$nhi,$nlo,#0xf0
@@ -298,11 +298,11 @@
 	ldmia	sp!,{r4-r11,lr}
 	tst	lr,#1
 	moveq	pc,lr			@ be binary compatible with V4, yet
 	bx	lr			@ interoperable with Thumb ISA:-)
 #endif
-.size	gcm_gmult_4bit,.-gcm_gmult_4bit
+@.size	_gcm_gmult_4bit,.-_gcm_gmult_4bit
 ___
 {
 my $cnt=$Htbl;	# $Htbl is used once in the very beginning
 
 my ($Hhi, $Hlo, $Zo, $T, $xi, $mod) = map("d$_",(0..7));
@@ -317,16 +317,16 @@
 sub Dhi()   { shift=~m|q([1]?[0-9])|?"d".($1*2+1):"";   }
 sub Q()     { shift=~m|d([1-3]?[02468])|?"q".($1/2):""; }
 
 $code.=<<___;
 #if __ARM_ARCH__>=7
-.fpu	neon
+@.fpu	neon
 
-.global	gcm_gmult_neon
-.type	gcm_gmult_neon,%function
+.globl	_gcm_gmult_neon
+@.type	_gcm_gmult_neon,%function
 .align	4
-gcm_gmult_neon:
+_gcm_gmult_neon:
 	sub		$Htbl,#16		@ point at H in GCM128_CTX
 	vld1.64		`&Dhi("$IN")`,[$Xi,:64]!@ load Xi
 	vmov.i32	$mod,#0xe1		@ our irreducible polynomial
 	vld1.64		`&Dlo("$IN")`,[$Xi,:64]!
 	vshr.u64	$mod,#32
@@ -341,16 +341,16 @@
 	veor		$Z,$Z
 	mov		$len,#16
 	veor		$Zo,$Zo
 	vdup.8		$xi,`&Dlo("$IN")`[0]	@ broadcast lowest byte
 	b		.Linner_neon
-.size	gcm_gmult_neon,.-gcm_gmult_neon
+@.size	_gcm_gmult_neon,.-_gcm_gmult_neon
 
-.global	gcm_ghash_neon
-.type	gcm_ghash_neon,%function
+.globl	_gcm_ghash_neon
+@.type	_gcm_ghash_neon,%function
 .align	4
-gcm_ghash_neon:
+_gcm_ghash_neon:
 	vld1.64		`&Dhi("$Z")`,[$Xi,:64]!	@ load Xi
 	vmov.i32	$mod,#0xe1		@ our irreducible polynomial
 	vld1.64		`&Dlo("$Z")`,[$Xi,:64]!
 	vshr.u64	$mod,#32
 	vldmia		$Xi,{$Hhi-$Hlo}		@ load H
@@ -412,11 +412,11 @@
 	sub		$Xi,#16	
 	vst1.64		`&Dhi("$Z")`,[$Xi,:64]!	@ write out Xi
 	vst1.64		`&Dlo("$Z")`,[$Xi,:64]
 
 	bx	lr
-.size	gcm_ghash_neon,.-gcm_ghash_neon
+@.size	_gcm_ghash_neon,.-_gcm_ghash_neon
 #endif
 ___
 }
 $code.=<<___;
 .asciz  "GHASH for ARMv4/NEON, CRYPTOGAMS by <appro\@openssl.org>"
diff -rU5 ./openssl-1.0.1-beta3/crypto/sha/asm/sha1-armv4-large.pl ./openssl-1.0.1-beta3-modified/crypto/sha/asm/sha1-armv4-large.pl
--- ./openssl-1.0.1-beta3/crypto/sha/asm/sha1-armv4-large.pl	2011-11-14 12:58:01.000000000 -0800
+++ ./openssl-1.0.1-beta3-modified/crypto/sha/asm/sha1-armv4-large.pl	2012-02-24 15:50:31.000000000 -0800
@@ -152,15 +152,15 @@
 $code=<<___;
 #include "arm_arch.h"
 
 .text
 
-.global	sha1_block_data_order
-.type	sha1_block_data_order,%function
+.globl	_sha1_block_data_order
+@.type	_sha1_block_data_order,%function
 
 .align	2
-sha1_block_data_order:
+_sha1_block_data_order:
 	stmdb	sp!,{r4-r12,lr}
 	add	$len,$inp,$len,lsl#6	@ $len to point at the end of $inp
 	ldmia	$ctx,{$a,$b,$c,$d,$e}
 .Lloop:
 	ldr	$K,.LK_00_19
@@ -236,11 +236,11 @@
 .align	2
 .LK_00_19:	.word	0x5a827999
 .LK_20_39:	.word	0x6ed9eba1
 .LK_40_59:	.word	0x8f1bbcdc
 .LK_60_79:	.word	0xca62c1d6
-.size	sha1_block_data_order,.-sha1_block_data_order
+@.size	_sha1_block_data_order,.-_sha1_block_data_order
 .asciz	"SHA1 block transform for ARMv4, CRYPTOGAMS by <appro\@openssl.org>"
 .align	2
 ___
 
 $code =~ s/\bbx\s+lr\b/.word\t0xe12fff1e/gm;	# make it possible to compile with -march=armv4
diff -rU5 ./openssl-1.0.1-beta3/crypto/sha/asm/sha256-armv4.pl ./openssl-1.0.1-beta3-modified/crypto/sha/asm/sha256-armv4.pl
--- ./openssl-1.0.1-beta3/crypto/sha/asm/sha256-armv4.pl	2011-11-14 12:58:01.000000000 -0800
+++ ./openssl-1.0.1-beta3-modified/crypto/sha/asm/sha256-armv4.pl	2012-02-24 15:50:03.000000000 -0800
@@ -125,11 +125,11 @@
 #include "arm_arch.h"
 
 .text
 .code	32
 
-.type	K256,%object
+@.type	K256,%object
 .align	5
 K256:
 .word	0x428a2f98,0x71374491,0xb5c0fbcf,0xe9b5dba5
 .word	0x3956c25b,0x59f111f1,0x923f82a4,0xab1c5ed5
 .word	0xd807aa98,0x12835b01,0x243185be,0x550c7dc3
@@ -144,16 +144,16 @@
 .word	0xd192e819,0xd6990624,0xf40e3585,0x106aa070
 .word	0x19a4c116,0x1e376c08,0x2748774c,0x34b0bcb5
 .word	0x391c0cb3,0x4ed8aa4a,0x5b9cca4f,0x682e6ff3
 .word	0x748f82ee,0x78a5636f,0x84c87814,0x8cc70208
 .word	0x90befffa,0xa4506ceb,0xbef9a3f7,0xc67178f2
-.size	K256,.-K256
+@.size	K256,.-K256
 
-.global	sha256_block_data_order
-.type	sha256_block_data_order,%function
-sha256_block_data_order:
-	sub	r3,pc,#8		@ sha256_block_data_order
+.globl	_sha256_block_data_order
+@.type	_sha256_block_data_order,%function
+_sha256_block_data_order:
+	sub	r3,pc,#8		@ _sha256_block_data_order
 	add	$len,$inp,$len,lsl#6	@ len to point at the end of inp
 	stmdb	sp!,{$ctx,$inp,$len,r4-r11,lr}
 	ldmia	$ctx,{$A,$B,$C,$D,$E,$F,$G,$H}
 	sub	$Ktbl,r3,#256		@ K256
 	sub	sp,sp,#16*4		@ alloca(X[16])
@@ -198,11 +198,11 @@
 	ldmia	sp!,{r4-r11,lr}
 	tst	lr,#1
 	moveq	pc,lr			@ be binary compatible with V4, yet
 	bx	lr			@ interoperable with Thumb ISA:-)
 #endif
-.size   sha256_block_data_order,.-sha256_block_data_order
+@.size   _sha256_block_data_order,.-_sha256_block_data_order
 .asciz  "SHA256 block transform for ARMv4, CRYPTOGAMS by <appro\@openssl.org>"
 .align	2
 ___
 
 $code =~ s/\`([^\`]*)\`/eval $1/gem;
diff -rU5 ./openssl-1.0.1-beta3/crypto/sha/asm/sha512-armv4.pl ./openssl-1.0.1-beta3-modified/crypto/sha/asm/sha512-armv4.pl
--- ./openssl-1.0.1-beta3/crypto/sha/asm/sha512-armv4.pl	2011-11-14 12:58:01.000000000 -0800
+++ ./openssl-1.0.1-beta3-modified/crypto/sha/asm/sha512-armv4.pl	2012-02-24 17:00:48.000000000 -0800
@@ -174,11 +174,11 @@
 # define WORD64(hi0,lo0,hi1,lo1)	.word	hi0,lo0, hi1,lo1
 #endif
 
 .text
 .code	32
-.type	K512,%object
+@.type	K512,%object
 .align	5
 K512:
 WORD64(0x428a2f98,0xd728ae22, 0x71374491,0x23ef65cd)
 WORD64(0xb5c0fbcf,0xec4d3b2f, 0xe9b5dba5,0x8189dbbc)
 WORD64(0x3956c25b,0xf348b538, 0x59f111f1,0xb605d019)
@@ -217,23 +217,23 @@
 WORD64(0x113f9804,0xbef90dae, 0x1b710b35,0x131c471b)
 WORD64(0x28db77f5,0x23047d84, 0x32caab7b,0x40c72493)
 WORD64(0x3c9ebe0a,0x15c9bebc, 0x431d67c4,0x9c100d4c)
 WORD64(0x4cc5d4be,0xcb3e42b6, 0x597f299c,0xfc657e2a)
 WORD64(0x5fcb6fab,0x3ad6faec, 0x6c44198c,0x4a475817)
-.size	K512,.-K512
+@.size	K512,.-K512
 .LOPENSSL_armcap:
-.word	OPENSSL_armcap_P-sha512_block_data_order
-.skip	32-4
+.word	_OPENSSL_armcap_P-_sha512_block_data_order
+.space	32-4
 
-.global	sha512_block_data_order
-.type	sha512_block_data_order,%function
-sha512_block_data_order:
-	sub	r3,pc,#8		@ sha512_block_data_order
+.globl	_sha512_block_data_order
+@.type	_sha512_block_data_order,%function
+_sha512_block_data_order:
+	sub	r3,pc,#8		@ _sha512_block_data_order
 	add	$len,$inp,$len,lsl#7	@ len to point at the end of inp
 #if __ARM_ARCH__>=7
 	ldr	r12,.LOPENSSL_armcap
-	ldr	r12,[r3,r12]		@ OPENSSL_armcap_P
+	ldr	r12,[r3,r12]		@ _OPENSSL_armcap_P
 	tst	r12,#1
 	bne	.LNEON
 #endif
 	stmdb	sp!,{r4-r12,lr}
 	sub	$Ktbl,r3,#672		@ K512
@@ -532,11 +532,11 @@
 	&NEON_00_15(2*$i,@_);
 }
 
 $code.=<<___;
 #if __ARM_ARCH__>=7
-.fpu	neon
+@.fpu	neon
 
 .align	4
 .LNEON:
 	dmb				@ errata #451034 on early Cortex A8
 	vstmdb	sp!,{d8-d15}		@ ABI specification says so
@@ -568,14 +568,14 @@
 	bx	lr
 #endif
 ___
 }
 $code.=<<___;
-.size	sha512_block_data_order,.-sha512_block_data_order
+@.size	_sha512_block_data_order,.-_sha512_block_data_order
 .asciz	"SHA512 block transform for ARMv4/NEON, CRYPTOGAMS by <appro\@openssl.org>"
 .align	2
-.comm	OPENSSL_armcap_P,4,4
+.lcomm	_OPENSSL_armcap_P,4,4
 ___
 
 $code =~ s/\`([^\`]*)\`/eval $1/gem;
 $code =~ s/\bbx\s+lr\b/.word\t0xe12fff1e/gm;	# make it possible to compile with -march=armv4
 print $code;
